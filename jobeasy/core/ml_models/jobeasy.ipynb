{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MveAMhu8c63H",
        "outputId": "7786f22c-9429-4413-f772-003ebfc93690"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification report for I-E dimension using LogisticRegression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           E       0.83      0.14      0.23       400\n",
            "           I       0.79      0.99      0.88      1335\n",
            "\n",
            "    accuracy                           0.79      1735\n",
            "   macro avg       0.81      0.56      0.56      1735\n",
            "weighted avg       0.80      0.79      0.73      1735\n",
            "\n",
            "\n",
            "Classification report for I-E dimension using RandomForest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           E       0.00      0.00      0.00       400\n",
            "           I       0.77      1.00      0.87      1335\n",
            "\n",
            "    accuracy                           0.77      1735\n",
            "   macro avg       0.38      0.50      0.43      1735\n",
            "weighted avg       0.59      0.77      0.67      1735\n",
            "\n",
            "\n",
            "Classification report for I-E dimension using SVM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           E       0.85      0.15      0.25       400\n",
            "           I       0.80      0.99      0.88      1335\n",
            "\n",
            "    accuracy                           0.80      1735\n",
            "   macro avg       0.82      0.57      0.57      1735\n",
            "weighted avg       0.81      0.80      0.74      1735\n",
            "\n",
            "\n",
            "Classification report for I-E dimension using CatBoost:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           E       0.71      0.35      0.47       400\n",
            "           I       0.83      0.96      0.89      1335\n",
            "\n",
            "    accuracy                           0.82      1735\n",
            "   macro avg       0.77      0.65      0.68      1735\n",
            "weighted avg       0.80      0.82      0.79      1735\n",
            "\n",
            "\n",
            "Classification report for N-S dimension using LogisticRegression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.86      1.00      0.93      1496\n",
            "           S       0.75      0.01      0.02       239\n",
            "\n",
            "    accuracy                           0.86      1735\n",
            "   macro avg       0.81      0.51      0.48      1735\n",
            "weighted avg       0.85      0.86      0.80      1735\n",
            "\n",
            "\n",
            "Classification report for N-S dimension using RandomForest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.86      1.00      0.93      1496\n",
            "           S       0.00      0.00      0.00       239\n",
            "\n",
            "    accuracy                           0.86      1735\n",
            "   macro avg       0.43      0.50      0.46      1735\n",
            "weighted avg       0.74      0.86      0.80      1735\n",
            "\n",
            "\n",
            "Classification report for N-S dimension using SVM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.86      1.00      0.93      1496\n",
            "           S       0.50      0.01      0.02       239\n",
            "\n",
            "    accuracy                           0.86      1735\n",
            "   macro avg       0.68      0.50      0.47      1735\n",
            "weighted avg       0.81      0.86      0.80      1735\n",
            "\n",
            "\n",
            "Classification report for N-S dimension using CatBoost:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.89      0.99      0.94      1496\n",
            "           S       0.77      0.25      0.37       239\n",
            "\n",
            "    accuracy                           0.89      1735\n",
            "   macro avg       0.83      0.62      0.66      1735\n",
            "weighted avg       0.87      0.89      0.86      1735\n",
            "\n",
            "\n",
            "Classification report for T-F dimension using LogisticRegression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           F       0.83      0.86      0.84       939\n",
            "           T       0.82      0.79      0.80       796\n",
            "\n",
            "    accuracy                           0.82      1735\n",
            "   macro avg       0.82      0.82      0.82      1735\n",
            "weighted avg       0.82      0.82      0.82      1735\n",
            "\n",
            "\n",
            "Classification report for T-F dimension using RandomForest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           F       0.70      0.90      0.79       939\n",
            "           T       0.82      0.54      0.65       796\n",
            "\n",
            "    accuracy                           0.73      1735\n",
            "   macro avg       0.76      0.72      0.72      1735\n",
            "weighted avg       0.75      0.73      0.72      1735\n",
            "\n",
            "\n",
            "Classification report for T-F dimension using SVM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           F       0.84      0.84      0.84       939\n",
            "           T       0.82      0.82      0.82       796\n",
            "\n",
            "    accuracy                           0.83      1735\n",
            "   macro avg       0.83      0.83      0.83      1735\n",
            "weighted avg       0.83      0.83      0.83      1735\n",
            "\n",
            "\n",
            "Classification report for T-F dimension using CatBoost:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           F       0.83      0.82      0.83       939\n",
            "           T       0.79      0.80      0.80       796\n",
            "\n",
            "    accuracy                           0.81      1735\n",
            "   macro avg       0.81      0.81      0.81      1735\n",
            "weighted avg       0.81      0.81      0.81      1735\n",
            "\n",
            "\n",
            "Classification report for J-P dimension using LogisticRegression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           J       0.85      0.47      0.61       687\n",
            "           P       0.73      0.94      0.83      1048\n",
            "\n",
            "    accuracy                           0.76      1735\n",
            "   macro avg       0.79      0.71      0.72      1735\n",
            "weighted avg       0.78      0.76      0.74      1735\n",
            "\n",
            "\n",
            "Classification report for J-P dimension using RandomForest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           J       0.73      0.15      0.24       687\n",
            "           P       0.63      0.96      0.76      1048\n",
            "\n",
            "    accuracy                           0.64      1735\n",
            "   macro avg       0.68      0.56      0.50      1735\n",
            "weighted avg       0.67      0.64      0.56      1735\n",
            "\n",
            "\n",
            "Classification report for J-P dimension using SVM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           J       0.82      0.47      0.60       687\n",
            "           P       0.73      0.93      0.82      1048\n",
            "\n",
            "    accuracy                           0.75      1735\n",
            "   macro avg       0.78      0.70      0.71      1735\n",
            "weighted avg       0.77      0.75      0.73      1735\n",
            "\n",
            "\n",
            "Classification report for J-P dimension using CatBoost:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           J       0.75      0.61      0.68       687\n",
            "           P       0.77      0.87      0.82      1048\n",
            "\n",
            "    accuracy                           0.77      1735\n",
            "   macro avg       0.76      0.74      0.75      1735\n",
            "weighted avg       0.76      0.77      0.76      1735\n",
            "\n",
            "Enter new post text: I seek to grow and evolve as an individual through a multifaceted approach that encompasses continuous learning, self-reflection, and meaningful experiences. Embracing new challenges and stepping out of my comfort zone allows me to expand my horizons and develop new skills. I prioritize self-reflection, regularly examining my beliefs, values, and behaviors to cultivate self-awareness and personal growth. Engaging in diverse experiences, whether through travel, exploration of different cultures, or participation in various activities, broadens my perspective and fosters empathy and understanding towards others. Additionally, I actively seek out opportunities for intellectual and emotional growth, such as reading, attending workshops, or engaging in meaningful conversations with others. By remaining open to change and embracing the journey of self-discovery, I aspire to become the best version of myself and make a positive impact on the world around me.\n",
            "\n",
            "Predicted MBTI Type (using Logistic Regression): INTP\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install nltk catboost scikit-learn\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import joblib\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from catboost import CatBoostClassifier\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Ensure NLTK resources are downloaded\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Text preprocessing functions\n",
        "def to_lower(text):\n",
        "    return text.lower()\n",
        "\n",
        "def remove_urls(text):\n",
        "    return re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    stop_words_set = set(nltk.corpus.stopwords.words('english'))\n",
        "    return ' '.join(word for word in text.split() if word not in stop_words_set)\n",
        "\n",
        "def remove_mbti_labels(text):\n",
        "    mbti_labels = ['infj', 'infp', 'intj', 'intp', 'isfj', 'isfp', 'istj', 'istp', 'enfj', 'enfp', 'entj', 'entp', 'esfj', 'esfp', 'estj', 'estp']\n",
        "    return ' '.join(word for word in text.split() if word not in mbti_labels)\n",
        "\n",
        "def remove_punct(text):\n",
        "    return ''.join(char for char in text if char not in string.punctuation)\n",
        "\n",
        "def remove_number(text):\n",
        "    return ''.join(char for char in text if not char.isdigit())\n",
        "\n",
        "def to_strip(text):\n",
        "    return ' '.join(text.split())\n",
        "\n",
        "def lemmatize(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = nltk.word_tokenize(text)\n",
        "    return ' '.join(lemmatizer.lemmatize(word) for word in words)\n",
        "\n",
        "def prepro(text):\n",
        "    return lemmatize(to_strip(remove_number(remove_punct(remove_mbti_labels(remove_stopwords(remove_urls(to_lower(str(text)))))))))\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('mbti_1.csv')\n",
        "\n",
        "# Define MBTI dimensions\n",
        "mbti_dimensions = ['I-E', 'N-S', 'T-F', 'J-P']\n",
        "for dim in mbti_dimensions:\n",
        "    data[dim] = data['type'].apply(lambda x: x[mbti_dimensions.index(dim)])\n",
        "\n",
        "data['clean'] = data['posts'].apply(prepro)\n",
        "\n",
        "# Define machine learning techniques to use\n",
        "ml_techniques = {\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=100),\n",
        "    \"SVM\": SVC(probability=True),\n",
        "    \"CatBoost\": CatBoostClassifier(iterations=500, verbose=False)  # Reduced iterations for quicker execution\n",
        "}\n",
        "\n",
        "# Train and evaluate models for each MBTI dimension and ML technique\n",
        "for dim in mbti_dimensions:\n",
        "    X = data['clean']\n",
        "    y = data[dim]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "    vectorizer = TfidfVectorizer(ngram_range=(1,1))\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)\n",
        "    X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "    # Serialize the vectorizer\n",
        "    joblib.dump(vectorizer, f'vectorizer_{dim}.pkl')\n",
        "\n",
        "    for technique_name, model in ml_techniques.items():\n",
        "        model.fit(X_train_vec, y_train)\n",
        "        # Serialize the model\n",
        "        joblib.dump(model, f'{dim}_{technique_name}.pkl')\n",
        "        # Predict and evaluate the model\n",
        "        predictions = model.predict(X_test_vec)\n",
        "        print(f\"\\nClassification report for {dim} dimension using {technique_name}:\")\n",
        "        print(classification_report(y_test, predictions))\n",
        "\n",
        "# Predicting a new post's MBTI type (example using Logistic Regression for 'I-E' dimension)\n",
        "new_post_text = input(\"Enter new post text: \")\n",
        "post_processed = prepro(new_post_text)\n",
        "\n",
        "final_mbti_type = ''\n",
        "for dim in mbti_dimensions:\n",
        "    vectorizer = joblib.load(f'vectorizer_{dim}.pkl')\n",
        "    model = joblib.load(f'{dim}_LogisticRegression.pkl')\n",
        "\n",
        "    post_vectorized = vectorizer.transform([post_processed])\n",
        "    prediction = model.predict(post_vectorized)[0]\n",
        "    final_mbti_type += prediction\n",
        "\n",
        "print(f\"\\nPredicted MBTI Type (using Logistic Regression): {final_mbti_type}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cn-wxWDmdVYN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}